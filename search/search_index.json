{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":""},{"location":"#pea-kina-aka-giant-panda","title":"Pea Kina aka 'Giant Panda'","text":"<p>Wrapper around <code>pandas</code> library, which detects separator, encoding and type of the file. It allows to get a group of files with a matching pattern (python or glob regex). It can read both local and remote files (HTTP/HTTPS, FTP/FTPS/SFTP or S3/S3N/S3A).</p> <p>The supported file types are <code>csv</code>, <code>excel</code>, <code>json</code>, <code>parquet</code> and <code>xml</code>.</p> <p>:information_source: If the desired type is not yet supported, feel free to open an issue or to directly open a PR with the code !</p>"},{"location":"#installation","title":"Installation","text":"<p><code>pip install peakina</code></p>"},{"location":"#usage","title":"Usage","text":"<p>Considering a file <code>file.csv</code></p> <pre><code>a;b\n0;0\n0;1\n</code></pre> <p>Just type</p> <pre><code>&gt;&gt;&gt; import peakina as pk\n&gt;&gt;&gt; pk.read_pandas('file.csv')\n   a  b\n0  0  0\n1  0  1\n</code></pre> <p>Or files on a FTPS server: - my_data_2015.csv - my_data_2016.csv - my_data_2017.csv - my_data_2018.csv</p> <p>You can just type</p> <pre><code>&gt;&gt;&gt; pk.read_pandas('ftps://&lt;path&gt;/my_data_\\\\d{4}\\\\.csv$', match='regex', dtype={'a': 'str'})\n    a   b     __filename__\n0  '0'  0  'my_data_2015.csv'\n1  '0'  1  'my_data_2015.csv'\n2  '1'  0  'my_data_2016.csv'\n3  '1'  1  'my_data_2016.csv'\n4  '3'  0  'my_data_2017.csv'\n5  '3'  1  'my_data_2017.csv'\n6  '4'  0  'my_data_2018.csv'\n7  '4'  1  'my_data_2018.csv'\n</code></pre>"},{"location":"#using-cache","title":"Using cache","text":"<p>You may want to keep the last result in cache, to avoid downloading and extracting the file if it didn't change:</p> <pre><code>&gt;&gt;&gt; from peakina.cache import Cache\n&gt;&gt;&gt; cache = Cache.get_cache('memory')  # in-memory cache\n&gt;&gt;&gt; df = pk.read_pandas('file.csv', expire=3600, cache=cache)\n</code></pre> <p>In this example, the resulting dataframe will be fetched from the cache, unless <code>file.csv</code> modification time has changed on disk, or unless the cache is older than 1 hour.</p> <p>For persistent caching, use: <code>cache = Cache.get_cache('hdf', cache_dir='/tmp')</code></p>"},{"location":"#use-only-downloading-feature","title":"Use only downloading feature","text":"<p>If you just want to download a file, without converting it to a pandas dataframe:</p> <pre><code>&gt;&gt;&gt; uri = 'https://i.imgur.com/V9x88.jpg'\n&gt;&gt;&gt; f = pk.fetch(uri)\n&gt;&gt;&gt; f.get_str_mtime()\n'2012-11-04T17:27:14Z'\n&gt;&gt;&gt; with f.open() as stream:\n...     print('Image size:', len(stream.read()), 'bytes')\n...\nImage size: 60284 bytes\n</code></pre>"}]}